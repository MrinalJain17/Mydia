{
    "docs": [
        {
            "location": "/",
            "text": "Video Utilities\n\n\nContains functions to read videos as NumPy arrays in Python\n\n\nInstructions\n\n\n\n\n\n\nClone the repository and navigate to the downloaded folder.\n\n\ngit clone https://github.com/MrinalJain17/video_utils.git\ncd video_utils\n\n\n\n\n\n\n\nIn order to read the videos, there is a helper class \nVideos\n in \nutils.py\n.\n\n\nimport numpy as np\nfrom utils import Videos\n\nreader = Videos(target_size=(150, 25), \n        to_gray=True, \n        max_frames=60, \n        extract_frames='first', \n        required_fps=0, \n        normalize_pixels=(0, 1))\n\npaths = [..]    # List of strings - each string being the path (absolute) of a video\nvideos = reader.read_videos(paths)\n\n\n\n\n\n\n\nView this \njupyter notebook\n to see how to get started\n\n\n\n\n\n\nRequirements\n\n\nPython 3.x\n (preferably from the \nAnaconda Distribution\n)\n\n\nScikit-video\n is used to read the videos, which requires \nFFmpeg\n to be installed on the system.\n\nTo install \nFFmpeg\n on your machine\n\n\nFor \nLinux\n:\n\n\n    $ sudo apt-get update\n    $ sudo apt-get install libav-tools\n\n\n\nFor \nWindows or MAC/OSX\n:  \n\n\nDownload the required binaries from \nhere\n. Extract the zip file and add the location of binaries to the \nPATH\n variable\n\n\nAdditional Libraries to install:\n\n\nSeveral libraries like \nNumpy\n, \nPillow\n come pre-installed with the Anaconda distribution of python.\n\nInstall the following extra packages:\n\n\n\n\n\n\nScikit-video\n\n\npip install sk-video\n\n\n\n\n\n\ntqdm\n - Required for displaying the progress bar.\n\n\npip install tqdm",
            "title": "Home"
        },
        {
            "location": "/#video-utilities",
            "text": "Contains functions to read videos as NumPy arrays in Python",
            "title": "Video Utilities"
        },
        {
            "location": "/#instructions",
            "text": "Clone the repository and navigate to the downloaded folder.  git clone https://github.com/MrinalJain17/video_utils.git\ncd video_utils    In order to read the videos, there is a helper class  Videos  in  utils.py .  import numpy as np\nfrom utils import Videos\n\nreader = Videos(target_size=(150, 25), \n        to_gray=True, \n        max_frames=60, \n        extract_frames='first', \n        required_fps=0, \n        normalize_pixels=(0, 1))\n\npaths = [..]    # List of strings - each string being the path (absolute) of a video\nvideos = reader.read_videos(paths)    View this  jupyter notebook  to see how to get started",
            "title": "Instructions"
        },
        {
            "location": "/#requirements",
            "text": "Python 3.x  (preferably from the  Anaconda Distribution )  Scikit-video  is used to read the videos, which requires  FFmpeg  to be installed on the system. \nTo install  FFmpeg  on your machine  For  Linux :      $ sudo apt-get update\n    $ sudo apt-get install libav-tools  For  Windows or MAC/OSX :    Download the required binaries from  here . Extract the zip file and add the location of binaries to the  PATH  variable",
            "title": "Requirements"
        },
        {
            "location": "/#additional-libraries-to-install",
            "text": "Several libraries like  Numpy ,  Pillow  come pre-installed with the Anaconda distribution of python. \nInstall the following extra packages:    Scikit-video  pip install sk-video    tqdm  - Required for displaying the progress bar.  pip install tqdm",
            "title": "Additional Libraries to install:"
        },
        {
            "location": "/usage/",
            "text": "Videos\n\n\nTo read in videos and store them as NumPy arrays.\n\n\nThe videos are stored as a 5-dimensional tensor - \n(<No. of Videos>, <No. of frames>, <height>, <width>, <channels>)\n.\n\nThe value of \nchannels\n could be 1 (gray scale) or 3 (RGB).\n\n\n\n\n\n\ntarget_size (tuple)\n: \n(New_Width, New_Height)\n. Defaults to \nNone\n.\nA tuple denoting the target width and height (of the frames) of the videos.\nIf not set, the dimensions of the frames will not be altered.\n\n\nNote:\n\n    A single video is a stack of frames. If the dimension of all the frames is not the same, they cannot by stacked.\n\n\n\n\n\n\nto_gray (boolean)\n: Whether to convert each video (all the frames) to gray scale or not. Defaults to \nFalse\n.\n\n\n\n\n\n\nmax_frames (int)\n: The (maximum) number of frames to extract from each video. Defaults to \nNone\n.\n\n\nFrames are extracted based on the value of \nextract_frames\n.\n\n\nIf not set, all the frames would be kept.\n\n\nNote:\n\n    Videos are stacked together. If the number of frames in all the videos are not the same, they cannot be stacked.\n\n\n\n\n\n\nextract_frames (str)\n: \n{'first', 'middle', 'last'}\n. Defaults to \n'middle'\n.\n\n\n'first'\n: Extract the frames from the beginning of the video. \n\n\n'last'\n: Extract the frames from the end of the video.  \n\n\n'middle'\n: Extract the frames from the middle of the video.  \n\n\nRemoves \n((total frames - 'max_frames') // 2)\n from the beginning ant the end of the video.\n\n\n\n\n\n\nrequired_fps (int)\n: The number of frame(s) to capture per second from the video. Defaults to \nNone\n.  \n\n\nFor each second of the video, only the first \n'N'\n frames are captured.  \n\n\nIf set to \n0\n, then the value of this parameter is \nadaptive to each video\n.\nIt will extract exactly \nmax_frames\n frames from each of the video (of any duration).\n\n\n\n\nE.g. Let the duration of a video to be 10 seconds assume it was captured at the rate of \n30fps\n.\n\n    Suppose the value of \nrequired_fps\n is set to 7.\n\n    Then, for each second, the first 7 frames would be captured.\n\n    The resulting video (in form of tensor) will have a total of \n10 * 7 = 70 frames\n.  \n\n\n\n\n\n\n\n\nnormalize_pixels (tuple, str)\n: Whether to normalize pixel values for each video or not. Defaults to \nNone\n.\n\n    The pixel values would be normalized based on the pixels of each video.\n\n\ntuple\n - \n(New_min, New_max)\n: Min-max normalization will be used.  \n\n\nstr\n - \n'z-score'\n: Z-score normalization will be used.  \n\n\nIf not set, then the pixels would not be normalized.  \n\n\n\n\n\n\nread_videos(paths)\n\n\nFunction to read videos.\n\n\nArgs\n:\n\n\n\n\npaths (list of str)\n: A list of paths of the videos to be read.\n\n\n\n\nReturns\n:\n\n\n\n\nNumpy.ndarray: A 5-dimensional tensor with shape \n(<No. of Videos>, <No. of frames>, <height>, <width>, <channels>)\n.\n\nThe value of \nchannels\n could be 1 (gray scale) or 3 (RGB).\n\n\n\n\nRaises\n:\n\n\n\n\nValueError\n: If the value of \nnormalize_pixels\n is invalid.\n\n\n\n\nget_frame_count(paths)\n\n\nGet the number of frames of all the videos.\n\n\nCan be used to determine the value of \nmax_frames\n.\n\n\nArgs\n:\n\n\n\n\npaths (list of str)\n: A list of paths of the videos to be read.\n\n\n\n\nReturns\n:\n\n\n\n\ndict (python dictionary)\n: Key - \npath of video\n, value - \nnumber of frames in that video\n.",
            "title": "Usage"
        },
        {
            "location": "/usage/#videos",
            "text": "To read in videos and store them as NumPy arrays.  The videos are stored as a 5-dimensional tensor -  (<No. of Videos>, <No. of frames>, <height>, <width>, <channels>) . \nThe value of  channels  could be 1 (gray scale) or 3 (RGB).    target_size (tuple) :  (New_Width, New_Height) . Defaults to  None .\nA tuple denoting the target width and height (of the frames) of the videos.\nIf not set, the dimensions of the frames will not be altered.  Note: \n    A single video is a stack of frames. If the dimension of all the frames is not the same, they cannot by stacked.    to_gray (boolean) : Whether to convert each video (all the frames) to gray scale or not. Defaults to  False .    max_frames (int) : The (maximum) number of frames to extract from each video. Defaults to  None .  Frames are extracted based on the value of  extract_frames .  If not set, all the frames would be kept.  Note: \n    Videos are stacked together. If the number of frames in all the videos are not the same, they cannot be stacked.    extract_frames (str) :  {'first', 'middle', 'last'} . Defaults to  'middle' .  'first' : Extract the frames from the beginning of the video.   'last' : Extract the frames from the end of the video.    'middle' : Extract the frames from the middle of the video.    Removes  ((total frames - 'max_frames') // 2)  from the beginning ant the end of the video.    required_fps (int) : The number of frame(s) to capture per second from the video. Defaults to  None .    For each second of the video, only the first  'N'  frames are captured.    If set to  0 , then the value of this parameter is  adaptive to each video .\nIt will extract exactly  max_frames  frames from each of the video (of any duration).   E.g. Let the duration of a video to be 10 seconds assume it was captured at the rate of  30fps . \n    Suppose the value of  required_fps  is set to 7. \n    Then, for each second, the first 7 frames would be captured. \n    The resulting video (in form of tensor) will have a total of  10 * 7 = 70 frames .       normalize_pixels (tuple, str) : Whether to normalize pixel values for each video or not. Defaults to  None . \n    The pixel values would be normalized based on the pixels of each video.  tuple  -  (New_min, New_max) : Min-max normalization will be used.    str  -  'z-score' : Z-score normalization will be used.    If not set, then the pixels would not be normalized.",
            "title": "Videos"
        },
        {
            "location": "/usage/#read_videospaths",
            "text": "Function to read videos.",
            "title": "read_videos(paths)"
        },
        {
            "location": "/usage/#args",
            "text": "paths (list of str) : A list of paths of the videos to be read.",
            "title": "Args:"
        },
        {
            "location": "/usage/#returns",
            "text": "Numpy.ndarray: A 5-dimensional tensor with shape  (<No. of Videos>, <No. of frames>, <height>, <width>, <channels>) . \nThe value of  channels  could be 1 (gray scale) or 3 (RGB).",
            "title": "Returns:"
        },
        {
            "location": "/usage/#raises",
            "text": "ValueError : If the value of  normalize_pixels  is invalid.",
            "title": "Raises:"
        },
        {
            "location": "/usage/#get_frame_countpaths",
            "text": "Get the number of frames of all the videos.  Can be used to determine the value of  max_frames .",
            "title": "get_frame_count(paths)"
        },
        {
            "location": "/usage/#args_1",
            "text": "paths (list of str) : A list of paths of the videos to be read.",
            "title": "Args:"
        },
        {
            "location": "/usage/#returns_1",
            "text": "dict (python dictionary) : Key -  path of video , value -  number of frames in that video .",
            "title": "Returns:"
        }
    ]
}