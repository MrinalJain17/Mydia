{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nGet started with some basics\n============================\n\nReading videos into NumPy arrays was never more simple. In addition,\nthis library also provides an entire range of additional functionalities\nfor reading the videos.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How to simple read a video, given its path?\n-------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import\nfrom mydia import Videos\nimport matplotlib.pyplot as plt\n\n# Initialize video path\nvideo_path = r'./sample_video/bigbuckbunny.mp4'\n\n# Create a reader object\nreader = Videos()\n\n# Call the 'read()' function to get the video tensor\nvideo = reader.read(video_path)\n\n# a tensor of shape (1, 132, 720, 1080, 3)\nprint(\"The shape of the tensor:\", video.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tensor represents **1 video** having **132 frames**, with each frame\nhaving a width and height of 1080 and 720 pixels respectively. \u201c**3**\u201d\ndenotes the Red, Green and Blue (RGB) channels of the video.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let\u2019s try to be a little more specific\n-------------------------------------------\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-  We want to resize each frame to be 720 pixels in width and 480 pixels\n   in height.\n-  Not all the frames are required. Let\u2019s just capture exactly 12 frames\n   (at equal intervals) from the video.\n-  And finally, we\u2019ll also visualize the captured frames.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import\nfrom mydia import Videos\nimport matplotlib.pyplot as plt\n\n# Initialize video path\nvideo_path = r'./sample_video/bigbuckbunny.mp4'\n\n# Configuring the parameters\n# Setting 'target_size' = (720, 480) : this denotes the new width and height of the frames\n# Setting 'num_frames' = 12 : to capture exactly 12 frames\n# For more detailed information, view the code documentation.\nreader = Videos(target_size=(720, 480), \n                num_frames=12)\n\n# Call the 'read()' function to get the required video tensor\nvideo = reader.read(video_path)   # a tensor of shape (1, 12, 480, 720, 3)\n\n# Plot the video frames in a grid\nreader.plot(video[0])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! Now let\u2019s read the same video in **gray scale**, instead of RGB.\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The number of channels for a video in gray scale is 1</p></div>\n (indicated by the last value in the tuple).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import\nfrom mydia import Videos\nimport matplotlib.pyplot as plt\n\n# Initialize video path\nvideo_path = r'./sample_video/bigbuckbunny.mp4'\n\n# Configuring the parameters\n# Other parameters are the same as described above.\n# The only additional parameter to modify is 'to_gray'\nreader = Videos(target_size=(720, 480), \n                to_gray=True, \n                num_frames=12)\n\n# Call the 'read()' function to get the required video tensor\nvideo = reader.read(video_path)   # a tensor of shape (1, 12, 480, 720, 1)\n\n# Plot the video frames in a grid\nreader.plot(video[0])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the loaded video tensor\n------------------------------\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. important:: Once the videos have been processed, they could be saved \n as :obj:`numpy.ndarray` (in .npz or .npy format). For further details, view \n the documentation of: \n\n - :obj:`numpy.save`: for saving in .npy format \n\n - :obj:`numpy.savez`: for saving in .npz format \n\n - :obj:`numpy.load`: for loading back the saved numpy tensors \n\n Since the whole reading process is time consuming, this could turn out to be \n a useful way to store and reload the video tensors. \n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}