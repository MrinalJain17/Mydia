{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nGet started with some basics\n============================\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Read a video, given its path\n-------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import\nfrom mydia import Videos\n\n# Initialize video path\nvideo_path = r\"./sample_video/bigbuckbunny.mp4\"\n\n# Create a reader object\nreader = Videos()\n\n# Call the 'read()' function to get the video tensor\nvideo = reader.read(video_path)\n\n# a tensor of shape (1, 132, 720, 1280, 3)\nprint(\"The shape of the tensor:\", video.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tensor can be interpreted as -\n\n* 1 video\n* Having 132 frames,\n* Dimension (width x height) of each frame: 1280x720 pixels\n* ``3`` denotes that the video is RGB\n\n2. Read multiple videos\n-----------------------\n\n.. code-block:: python\n\n   from mydia import Videos\n\n   video_paths = [\n       \"path/to/video_1\",\n       \"path/to/video_2\",\n       \"path/to/video_3\",\n       ...,\n   ]          # list of path of videos\n\n   reader = Videos()\n   video = reader.read(video_paths)\n\n3. Use multiple workers for reading the videos in parallel\n----------------------------------------------------------\n\n.. code-block:: python\n   :emphasize-lines: 11\n\n   from mydia import Videos\n\n   video_paths = [\n       \"path/to/video_1\",\n       \"path/to/video_2\",\n       \"path/to/video_3\",\n       ...,\n   ]          # list of path of videos\n\n   reader = Videos()\n   video = reader.read(video_paths, workers=4)\n\n**The code above will use 4 CPUs to read the videos in parallel,\nwhich could result in a significant speed up, depending on the\nvideos to be read and the performance of the CPU.**\n\n4. Use a python generator for multiple videos\n---------------------------------------------\n\n.. code-block:: python\n\n   from mydia import Videos\n\n   video_paths = [\n       \"path/to/video_1\",\n       \"path/to/video_2\",\n       \"path/to/video_3\",\n       ...,\n   ]          # list of path of videos\n\n   reader = Videos()\n\n   def generate_video():\n       for path in video_paths:\n           video = reader.read(path)\n           yield video\n\n   for i in range(len(video_paths)):\n       vid = next(generate_video())\n       # Do something\n\n*For information on the parameters available, read the examples ahead\nand also refer to the documentation of the class* :class:`mydia.Videos`.\n\n\nSaving the loaded video tensor\n------------------------------\n\n.. important:: Once the videos have been processed, they could be\n saved as :obj:`numpy.ndarray` (in `.npz` or `.npy` format). For\n further details, view the documentation of:\n\n * :obj:`numpy.save`: for saving in `.npy` format\n\n * :obj:`numpy.savez`: for saving in `.npz` format\n\n * :obj:`numpy.load`: for loading back the saved numpy tensors\n\n Since the whole reading process is time consuming, this could turn\n out to be a useful way to store and reload the video tensors.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}